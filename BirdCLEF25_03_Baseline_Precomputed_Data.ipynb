{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1EM51knAqkgdgKR_LEsvL0B8NRH_-0_to",
      "authorship_tag": "ABX9TyPbgWfl/QHNUsWtNQXs4pbI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bachaudhry/kaggle_birdCLEF_25/blob/main/BirdCLEF25_03_Baseline_Precomputed_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MPhonWFFUZEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.environ[\"KAGGLE_CONFIG_DIR\"] = \"/content/drive/MyDrive/Kaggle\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jOrk6FGUW24",
        "outputId": "57b71d44-5dfe-4f56-d56b-8ff6026d19d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "QKPHMfMtgmSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys, gc, random, math, time, copy , zipfile, tarfile, shutil, subprocess, json\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "import IPython.display as ipd\n",
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import soundfile as sf\n",
        "\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.multiprocessing as mp\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.amp as amp\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, average_precision_score\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "F0dtrnjeUFrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('/content/drive/MyDrive/Kaggle/Bird_CLEF25/utils')\n",
        "from utils import Config, BirdClefDataset, create_target_tensor, seed_everything, process_gzipped"
      ],
      "metadata": {
        "id": "4VY8jZA4fZWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = Config()\n",
        "# Path to original train.csv, audio and metadata\n",
        "cfg.BASE_DATA_PATH = Path(\"/content/drive/MyDrive/Kaggle/Bird_CLEF25/data/birdclef-2025\")\n",
        "# Path to npy files\n",
        "cfg.PRECOMPUTED_SPECS_PATH = Path(\"/content/drive/MyDrive/Kaggle/Bird_CLEF25/data/precomputed-specs-np-zipped\")\n",
        "# Path to local specs\n",
        "#cfg.LOCAL_SPECS_PATH = Path(\"/content/precomputed_spectrograms\")\n",
        "# Training meta data\n",
        "cfg.TRAIN_METADATA_PATH = Path(\"/content/drive/MyDrive/Kaggle/Bird_CLEF25/data/birdclef-2025/train.csv\")"
      ],
      "metadata": {
        "id": "LmOAPiLPfZTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Set Device & Seed ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "seed_everything(cfg.SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYdzB_OafZQ_",
        "outputId": "9bec4ddc-e74b-42f1-f077-9ad6266181bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Seeded everything with: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if cfg.NUM_WORKERS > 0:\n",
        "    try:\n",
        "        current_context = mp.get_context(None)\n",
        "        if not isinstance(current_context, mp.SpawnContext):\n",
        "             mp.set_start_method('spawn', force=True)\n",
        "             print(\"Set multiprocessing start method to 'spawn'.\")\n",
        "        else:\n",
        "             print(\"Multiprocessing start method already set to 'spawn'.\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Could not set start method (might be already set or first run): {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRsuayJcfZOS",
        "outputId": "891a21c7-cf8e-46c7-8249-7b0d3b4b1f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Set multiprocessing start method to 'spawn'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load Metadata ---\n",
        "if not cfg.TRAIN_METADATA_PATH.exists():\n",
        "    print(f\"ERROR: Metadata file not found at {cfg.TRAIN_METADATA_PATH}\")\n",
        "    # Stop execution or handle\n",
        "else:\n",
        "    train_df = pd.read_csv(cfg.TRAIN_METADATA_PATH)\n",
        "    print(f\"Train metadata loaded. Shape: {train_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjDZIs1ZfZL7",
        "outputId": "c89911f7-0992-45e6-efb0-2e01380563f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train metadata loaded. Shape: (28564, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!apt-get install pigz rsync -qq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KLLUKKsW4S07",
        "outputId": "fbe39dd3-9ac9-402f-ed6f-7acbd57342b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "## Testing improved download and unzip function\n",
        "def process_gzippedV2(file_id, output_path=None):\n",
        "  local_temp_dir = \"/content/temp_data\"\n",
        "  local_extract_path = os.path.join(local_temp_dir, \"extracted\")\n",
        "  os.makedirs(local_extract_path, exist_ok=True)\n",
        "\n",
        "  # Download using gdown\n",
        "  print(\"Downloading compressed file from Google Drive...\")\n",
        "  url = f'https://drive.google.com/uc?id={file_id.split(\"/\")[-2]}'\n",
        "  compressed_path = gdown.download(url, output=local_temp_dir, quiet=False)\n",
        "\n",
        "  # Ensure compressed_path is a file, not the directory\n",
        "  compressed_path = os.path.join(local_temp_dir, compressed_path)  # Corrected line\n",
        "\n",
        "  # Extract with parallel decompression (if possible/available)\n",
        "  print(f\"Extracting {os.path.basename(compressed_path)}...\")\n",
        "  try:\n",
        "    # Using pigz for parallel decompression\n",
        "    subprocess.run(['pigz', '--version'], check=True)\n",
        "    subprocess.run(['tar', '-I', 'pigz', '-xf', compressed_path, '-C', local_extract_path],\n",
        "                   check=True)\n",
        "  except:\n",
        "    # Fallback to tar\n",
        "    subprocess.run(['tar', '-xzf', compressed_path, '-C', local_extract_path],\n",
        "                   check=True)\n",
        "\n",
        "  # Clean up compressed file\n",
        "  os.remove(compressed_path)\n",
        "\n",
        "  # Optional upload to drive\n",
        "  if output_path:\n",
        "        print(\"⏫ Starting Drive upload...\")\n",
        "        drive_output_path = os.path.join('/content/drive/MyDrive', output_path)\n",
        "\n",
        "        # Use parallel upload with rsync\n",
        "        subprocess.run([\n",
        "            'rsync', '-a', '--info=progress2',\n",
        "            local_extract_path + '/',\n",
        "            drive_output_path\n",
        "        ], check=True)\n",
        "\n",
        "  print(\"✅ All operations completed!\")\n",
        "  return local_extract_path\n"
      ],
      "metadata": {
        "id": "XBum5eud3TaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = 'https://drive.google.com/file/d/1Ji5acgpHlyyhd8vI8gyQlN1nkjh16MwN/view?usp=drive_link'\n",
        "local_extract = process_gzippedV2(file_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "DoLJ2yFf3TUT",
        "outputId": "1d45c751-a6b3-4981-9fcb-7559a37d2146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading compressed file from Google Drive...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileURLRetrievalError",
          "evalue": "Failed to retrieve file url:\n\n\tToo many users have viewed or downloaded this file recently. Please\n\ttry accessing the file again later. If the file you are trying to\n\taccess is particularly large or is shared with many people, it may\n\ttake up to 24 hours to be able to view or download the file. If you\n\tstill can't access a file after 24 hours, contact your domain\n\tadministrator.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=1Ji5acgpHlyyhd8vI8gyQlN1nkjh16MwN\n\nbut Gdown can't. Please check connections and permissions.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_url_from_gdrive_confirmation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mget_url_from_gdrive_confirmation\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Too many users have viewed or downloaded this file recently. Please try accessing the file again later. If the file you are trying to access is particularly large or is shared with many people, it may take up to 24 hours to be able to view or download the file. If you still can't access a file after 24 hours, contact your domain administrator.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-49320e248352>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://drive.google.com/file/d/1Ji5acgpHlyyhd8vI8gyQlN1nkjh16MwN/view?usp=drive_link'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlocal_extract\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_gzippedV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-bd13ee7a4ae6>\u001b[0m in \u001b[0;36mprocess_gzippedV2\u001b[0;34m(file_id, output_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading compressed file from Google Drive...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'https://drive.google.com/uc?id={file_id.split(\"/\")[-2]}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mcompressed_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_temp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m# Ensure compressed_path is a file, not the directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0murl_origin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             )\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mfilename_from_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Failed to retrieve file url:\n\n\tToo many users have viewed or downloaded this file recently. Please\n\ttry accessing the file again later. If the file you are trying to\n\taccess is particularly large or is shared with many people, it may\n\ttake up to 24 hours to be able to view or download the file. If you\n\tstill can't access a file after 24 hours, contact your domain\n\tadministrator.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=1Ji5acgpHlyyhd8vI8gyQlN1nkjh16MwN\n\nbut Gdown can't. Please check connections and permissions."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JnoctVNz3TPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gPVas5X13TGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download zipped folder and extract to local\n",
        "input_path = \"/content/drive/MyDrive/Kaggle/Bird_CLEF25/data/precomputed-specs-np-zipped\"\n",
        "local_extract = process_gzipped(input_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynDHKvxkJMqN",
        "outputId": "fc3e6048-d223-47ac-cb6d-f62b00a86911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying precomputed-specs-np-zipped from Drive to Colab...\n",
            "Extracting precomputed-specs-np-zipped...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting files: 100%|██████████| 187905/187905 [06:03<00:00, 517.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Operation completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update precomputed specs path\n",
        "#cfg.PRECOMPUTED_SPECS_PATH = cfg.LOCAL_SPECS_PATH\n",
        "# Run check\n",
        "local_specs_path = Path(\"/content/temp_data/extracted/kaggle/working/precomputed_specs_np\")\n",
        "all_precomputed_files = list(local_specs_path.glob(\"*.npy\"))\n",
        "print(f\"Found {len(all_precomputed_files)} precomputed .npy files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLlg8hWRfZJY",
        "outputId": "769100d5-8db4-4a19-f045-287252023957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 187904 precomputed .npy files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create label mappings\n",
        "unique_labels = sorted(train_df['primary_label'].unique())\n",
        "cfg.NUM_CLASSES = len(unique_labels)\n",
        "cfg.LABEL_TO_INT = {label: i for i, label in enumerate(unique_labels)}\n",
        "cfg.INT_TO_LABEL = {i: label for label, i in cfg.LABEL_TO_INT.items()}\n",
        "train_df['primary_label_int'] = train_df['primary_label'].map(cfg.LABEL_TO_INT)\n",
        "print(f\"{cfg.NUM_CLASSES} unique classes found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOOBGzhUfZEx",
        "outputId": "501e6ad4-fd9f-415e-b021-65c0d2aebe21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "206 unique classes found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JidV7iDCaIHC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}